{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "from math import *\n",
    "import operator\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline \n",
    "\n",
    "import seaborn as sns\n",
    "sns.set(style=\"white\", color_codes=True)\n",
    "\n",
    "from pandas.plotting import scatter_matrix\n",
    "from sklearn import preprocessing, cross_validation\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "from sklearn.neighbors import KNeighborsClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\n4. Relevant Information:\\n   Samples arrive periodically as Dr. Wolberg reports his clinical cases.\\n   The database therefore reflects this chronological grouping of the data.\\n   This grouping information appears immediately below, having been removed\\n   from the data itself:\\n     Group 1: 367 instances (January 1989)\\n     Group 2:  70 instances (October 1989)\\n     Group 3:  31 instances (February 1990)\\n     Group 4:  17 instances (April 1990)\\n     Group 5:  48 instances (August 1990)\\n     Group 6:  49 instances (Updated January 1991)\\n     Group 7:  31 instances (June 1991)\\n     Group 8:  86 instances (November 1991)\\n     -----------------------------------------\\n     Total:   699 points (as of the donated datbase on 15 July 1992)\\n\\n   Note that the results summarized above in Past Usage refer to a dataset\\n   of size 369, while Group 1 has only 367 instances.  This is because it\\n   originally contained 369 instances; 2 were removed.  The following\\n   statements summarizes changes to the original Group 1\\'s set of data:\\n\\n   #####  Group 1 : 367 points: 200B 167M (January 1989)\\n   #####  Revised Jan 10, 1991: Replaced zero bare nuclei in 1080185 & 1187805\\n   #####  Revised Nov 22,1991: Removed 765878,4,5,9,7,10,10,10,3,8,1 no record\\n   #####                  : Removed 484201,2,7,8,8,4,3,10,3,4,1 zero epithelial\\n   #####                  : Changed 0 to 1 in field 6 of sample 1219406\\n   #####                  : Changed 0 to 1 in field 8 of following sample:\\n   #####                  : 1182404,2,3,1,1,1,2,0,1,1,1\\n\\n5. Number of Instances: 699 (as of 15 July 1992)\\n6. Number of Attributes: 10 plus the class attribute\\n7. Attribute Information: (class attribute has been moved to last column)\\n   #  Attribute                     Domain\\n   -- -----------------------------------------\\n   1. Sample code number            id number\\n   2. Clump Thickness               1 - 10\\n   3. Uniformity of Cell Size       1 - 10\\n   4. Uniformity of Cell Shape      1 - 10\\n   5. Marginal Adhesion             1 - 10\\n   6. Single Epithelial Cell Size   1 - 10\\n   7. Bare Nuclei                   1 - 10\\n   8. Bland Chromatin               1 - 10\\n   9. Normal Nucleoli               1 - 10\\n  10. Mitoses                       1 - 10\\n  11. Class:                        (2 for benign, 4 for malignant)\\n\\n8. Missing attribute values: 16\\n   There are 16 instances in Groups 1 to 6 that contain a single missing \\n   (i.e., unavailable) attribute value, now denoted by \"?\".  \\n9. Class distribution:\\n\\n   Benign: 458 (65.5%)\\n   Malignant: 241 (34.5%)\\n'"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''\n",
    "4. Relevant Information:\n",
    "   Samples arrive periodically as Dr. Wolberg reports his clinical cases.\n",
    "   The database therefore reflects this chronological grouping of the data.\n",
    "   This grouping information appears immediately below, having been removed\n",
    "   from the data itself:\n",
    "     Group 1: 367 instances (January 1989)\n",
    "     Group 2:  70 instances (October 1989)\n",
    "     Group 3:  31 instances (February 1990)\n",
    "     Group 4:  17 instances (April 1990)\n",
    "     Group 5:  48 instances (August 1990)\n",
    "     Group 6:  49 instances (Updated January 1991)\n",
    "     Group 7:  31 instances (June 1991)\n",
    "     Group 8:  86 instances (November 1991)\n",
    "     -----------------------------------------\n",
    "     Total:   699 points (as of the donated datbase on 15 July 1992)\n",
    "\n",
    "   Note that the results summarized above in Past Usage refer to a dataset\n",
    "   of size 369, while Group 1 has only 367 instances.  This is because it\n",
    "   originally contained 369 instances; 2 were removed.  The following\n",
    "   statements summarizes changes to the original Group 1's set of data:\n",
    "\n",
    "   #####  Group 1 : 367 points: 200B 167M (January 1989)\n",
    "   #####  Revised Jan 10, 1991: Replaced zero bare nuclei in 1080185 & 1187805\n",
    "   #####  Revised Nov 22,1991: Removed 765878,4,5,9,7,10,10,10,3,8,1 no record\n",
    "   #####                  : Removed 484201,2,7,8,8,4,3,10,3,4,1 zero epithelial\n",
    "   #####                  : Changed 0 to 1 in field 6 of sample 1219406\n",
    "   #####                  : Changed 0 to 1 in field 8 of following sample:\n",
    "   #####                  : 1182404,2,3,1,1,1,2,0,1,1,1\n",
    "\n",
    "5. Number of Instances: 699 (as of 15 July 1992)\n",
    "6. Number of Attributes: 10 plus the class attribute\n",
    "7. Attribute Information: (class attribute has been moved to last column)\n",
    "   #  Attribute                     Domain\n",
    "   -- -----------------------------------------\n",
    "   1. Sample code number            id number\n",
    "   2. Clump Thickness               1 - 10\n",
    "   3. Uniformity of Cell Size       1 - 10\n",
    "   4. Uniformity of Cell Shape      1 - 10\n",
    "   5. Marginal Adhesion             1 - 10\n",
    "   6. Single Epithelial Cell Size   1 - 10\n",
    "   7. Bare Nuclei                   1 - 10\n",
    "   8. Bland Chromatin               1 - 10\n",
    "   9. Normal Nucleoli               1 - 10\n",
    "  10. Mitoses                       1 - 10\n",
    "  11. Class:                        (2 for benign, 4 for malignant)\n",
    "\n",
    "8. Missing attribute values: 16\n",
    "   There are 16 instances in Groups 1 to 6 that contain a single missing \n",
    "   (i.e., unavailable) attribute value, now denoted by \"?\".  \n",
    "9. Class distribution:\n",
    "\n",
    "   Benign: 458 (65.5%)\n",
    "   Malignant: 241 (34.5%)\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "location = r\"E:\\MYLEARN\\2-ANALYTICS-DataScience\\datasets\\breastcancer_orig.csv\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load the training data from breast cancer data set\n",
    "df_training = pd.read_csv(location)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Handle missing value\n",
    "df_training.replace('?', -99999, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# remove the code column\n",
    "df_training.drop(['code'], axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "690"
      ]
     },
     "execution_count": 86,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_training.shape[0]-1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extract % samples as test from the training file\n",
    "\n",
    "pct_test = 20\n",
    "test_patterns = (df_training.shape[0]-1) * pct_test/100\n",
    "\n",
    "index_list = random.sample(range(0, df_training.shape[0]-1), int(test_patterns))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Empty DataFrame\n",
       "Columns: []\n",
       "Index: []"
      ]
     },
     "execution_count": 102,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# initialize a test dataframe\n",
    "df_test = pd.DataFrame()\n",
    "df_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# copy the n training samples as test & drop the rows from the training df\n",
    "for elem in index_list:\n",
    "    df_test = df_test.append(df_training.iloc[elem: elem+1])\n",
    "\n",
    "# drop the rows from the training set (which r now in test dataframe)\n",
    "df_training.drop(df_training.index[index_list], inplace=True)     "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(553, 11)\n",
      "(138, 13)\n"
     ]
    }
   ],
   "source": [
    "df_training = df_training.reset_index(drop=True)\n",
    "df_test = df_test.reset_index(drop=True)\n",
    "\n",
    "print(df_training.shape)\n",
    "print(df_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# add a column for 'predicted_class'\n",
    "df_test['predicated_class'] = ''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df_training['distance'] = 0\n",
    "\n",
    "# set the value of k number of neighbors to choose\n",
    "k = 4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wall time: 52.4 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "features_list = ['Clump_Thickness','Cell_Size','Cell_Shape','Adhesion','Epithelial_Cell_Size','Bare_Nuclei',\n",
    "                 'Bland_Chromatin', 'Normal_Nucleoli','Mitoses']\n",
    "# for each test sample\n",
    "for index_test, row_test in df_test.iterrows():\n",
    "\n",
    "    # for each row in the dataframe, calculate the distance\n",
    "    for index, row in df_training.iterrows():\n",
    "        # initialize dist_sq \n",
    "        dist_sq = 0\n",
    "        for feature in features_list:\n",
    "            dist_sq = dist_sq + (float(row_test[feature]) - float(row[feature])) ** 2\n",
    "                              \n",
    "            \n",
    "        eucDist = sqrt(dist_sq)\n",
    "        df_training.loc[index, 'distance'] = eucDist\n",
    "    \n",
    "    # sort on distance, ascending.\n",
    "    df_training.sort_values('distance', ascending=True, inplace=True)\n",
    "    \n",
    "    # select the first k rows, into a new df\n",
    "    df_training_k = df_training.iloc[0:k, :].copy()\n",
    "    \n",
    "    df_training_k_grouped = df_training_k['Class']\n",
    "    \n",
    "    # predicted class\n",
    "    pred_class = df_training_k_grouped.max()\n",
    "    \n",
    "    # save the predicated class in the test data frame\n",
    "    df_test.at[index_test, 'predicted_class'] = pred_class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# “accuracy” as a metric. \n",
    "# Accuracy is the ratio of no. of data points correctly classified to total no. of data points.\n",
    "# on test data set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy =  97.83 %\n"
     ]
    }
   ],
   "source": [
    "# find the mismatch count of class predication\n",
    "no_mismatch_class = df_test.loc[~(df_test['predicted_class'] == df_test['Class'])].shape[0]\n",
    "\n",
    "# accuracy of prediction\n",
    "accuracy_pct = 100-(no_mismatch_class/ df_test.shape[0])*100\n",
    "\n",
    "print('Accuracy = {:6.2f} %'.format(accuracy_pct))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
